{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd301808",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib_venn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d349b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc, precision_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib_venn as venn\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "# Load Data \n",
    "df = pd.read_csv(\"/Users/pavitraaritas/Documents/PavitraAritasRaghunathSharma-CS438/Data/Data_CourseCompatibility.csv\")\n",
    "\n",
    "display(df.head())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30629ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution for Suitable_1 (BP course)\n",
    "print(\"\\nClass distribution for Suitable_1 (BP course):\")\n",
    "print(df['Suitable_1'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b78cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean & Preprocess Data\n",
    "\n",
    "# Define feature and target columns for BP course (Suitable_1)\n",
    "categorical_cols = ['Semester', 'LearningStyle', 'CareerTrack', 'Reason_1']\n",
    "numerical_cols = ['OverallCourseRating', 'InterestLevel_1']\n",
    "target_col = 'Suitable_1'\n",
    "\n",
    "def convert_study_hours(hours):\n",
    "    if pd.isna(hours):\n",
    "        return np.nan\n",
    "    hours = str(hours).lower().strip()\n",
    "    if 'hours' in hours:\n",
    "        hours = hours.replace('hours', '').strip()\n",
    "    if '-' in hours:\n",
    "        low, high = hours.split('-')\n",
    "        try:\n",
    "            return (float(low) + float(high)) / 2\n",
    "        except:\n",
    "            return np.nan\n",
    "    if '+' in hours:\n",
    "        return float(hours.replace('+', ''))\n",
    "    if '<' in hours:\n",
    "        return float(hours.replace('<', '')) - 1\n",
    "    try:\n",
    "        return float(hours)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df['StudyHours'] = df['StudyHours'].apply(convert_study_hours)\n",
    "numerical_cols.append('StudyHours')\n",
    "\n",
    "# Handle Missing Values \n",
    "df = df.dropna(subset=[target_col])\n",
    "\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "for col in numerical_cols:\n",
    "    df[col] = df[col].fillna(df[col].mean())\n",
    "\n",
    "print(\"\\nUnique values in Suitable_1 before mapping:\")\n",
    "print(df[target_col].unique())\n",
    "\n",
    "df[target_col] = df[target_col].map({'Yes': 1, 'No': 0})\n",
    "df = df.dropna(subset=[target_col])\n",
    "\n",
    "df_encoded = pd.get_dummies(df[categorical_cols], drop_first=True)\n",
    "\n",
    "X = pd.concat([df[numerical_cols], df_encoded], axis=1)\n",
    "y = df[target_col]\n",
    "\n",
    "X['StudyHours'] = X['StudyHours'].clip(upper=50)\n",
    "\n",
    "print(\"\\nMissing values in X after preprocessing:\")\n",
    "print(X.isna().sum())\n",
    "print(\"\\nPreprocessed Features (first 5 rows):\")\n",
    "display(X.head())\n",
    "print(\"\\nTarget (first 5 rows):\")\n",
    "print(y.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efef54b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitting for Tuning\n",
    "\n",
    "# Split into train (60%), validation (20%), and test (20%) sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=42)\n",
    "\n",
    "print(f\"\\nTraining set size: {len(X_train)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645eedf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "# Tune Logistic Regression \n",
    "lr_param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "lr_grid = GridSearchCV(LogisticRegression(max_iter=1000), lr_param_grid, cv=3, scoring='accuracy')\n",
    "lr_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Logistic Regression:\", lr_grid.best_params_)\n",
    "print(\"Best validation accuracy:\", lr_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230cee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation accuracy for different C values\n",
    "lr_results = pd.DataFrame(lr_grid.cv_results_)\n",
    "plt.figure(figsize=(8, 5))\n",
    "for penalty in ['l1', 'l2']:\n",
    "    mask = lr_results['param_penalty'] == penalty\n",
    "    plt.plot(lr_results[mask]['param_C'], lr_results[mask]['mean_test_score'], label=f'Penalty: {penalty}')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('C (Inverse of Regularization Strength)')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('Logistic Regression Hyperparameter Tuning')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816c6029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune Decision Tree \n",
    "dt_param_grid = {\n",
    "    'max_depth': [2, 3, 4, 5, 6],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "dt_grid = GridSearchCV(DecisionTreeClassifier(random_state=42), dt_param_grid, cv=3, scoring='accuracy')\n",
    "dt_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best parameters for Decision Tree:\", dt_grid.best_params_)\n",
    "print(\"Best validation accuracy:\", dt_grid.best_score_)\n",
    "\n",
    "# Plot validation accuracy for different max_depth\n",
    "dt_results = pd.DataFrame(dt_grid.cv_results_)\n",
    "plt.figure(figsize=(8, 5))\n",
    "for min_samples in [2, 5, 10]:\n",
    "    mask = dt_results['param_min_samples_split'] == min_samples\n",
    "    plt.plot(dt_results[mask]['param_max_depth'], dt_results[mask]['mean_test_score'], label=f'min_samples_split: {min_samples}')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('Decision Tree Hyperparameter Tuning')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1403381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progressive Modeling with Tuned Models\n",
    "results = {}\n",
    "models = {}\n",
    "\n",
    "# Logistic Regression (Tuned) \n",
    "print(\"\\n=== Stage 1: Tuned Logistic Regression ===\")\n",
    "model_lr = LogisticRegression(**lr_grid.best_params_, max_iter=1000)\n",
    "model_lr.fit(X_train, y_train)\n",
    "y_pred_lr = model_lr.predict(X_val)\n",
    "\n",
    "accuracy_lr = accuracy_score(y_val, y_pred_lr)\n",
    "results['Logistic Regression (Tuned)'] = accuracy_lr\n",
    "models['Logistic Regression'] = model_lr\n",
    "print(f\"Validation Accuracy: {accuracy_lr:.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred_lr))\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(confusion_matrix(y_val, y_pred_lr), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix (Tuned Logistic Regression)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e7a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Logistic Regression with K-Fold Cross-Validation \n",
    "print(\"\\n=== Stage 2: Logistic Regression with K-Fold Cross-Validation ===\")\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores_lr_kfold = cross_val_score(model_lr, X_temp, y_temp, cv=skf, scoring='accuracy')\n",
    "accuracy_lr_kfold = np.mean(scores_lr_kfold)\n",
    "results['Logistic Regression (K-Fold)'] = accuracy_lr_kfold\n",
    "print(f\"Average Accuracy (5-Fold CV): {accuracy_lr_kfold:.3f}\")\n",
    "print(f\"Standard Deviation: {np.std(scores_lr_kfold):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4851c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Decision Tree - Tuned\n",
    "print(\"\\n=== Stage 3: Tuned Decision Tree ===\")\n",
    "model_dt = DecisionTreeClassifier(**dt_grid.best_params_, random_state=42)\n",
    "model_dt.fit(X_train, y_train)\n",
    "y_pred_dt = model_dt.predict(X_val)\n",
    "\n",
    "accuracy_dt = accuracy_score(y_val, y_pred_dt)\n",
    "results['Decision Tree (Tuned)'] = accuracy_dt\n",
    "models['Decision Tree'] = model_dt\n",
    "print(f\"Validation Accuracy: {accuracy_dt:.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred_dt))\n",
    "\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(confusion_matrix(y_val, y_pred_dt), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix (Tuned Decision Tree)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9b110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Results for Validation Set\n",
    "for model, acc in results.items():\n",
    "    print(f\"{model}: {acc:.3f}\")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(results.keys(), results.values())\n",
    "plt.title(\"Model Accuracy Comparison (Validation Set)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147a530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "\n",
    "print(\"\\nFeature Importance (Logistic Regression):\")\n",
    "importances_lr = pd.Series(model_lr.coef_[0], index=X.columns)\n",
    "importances_lr.sort_values().plot(kind='barh', figsize=(10, 6))\n",
    "plt.title(\"Feature Importance (Logistic Regression)\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFeature Importance (Decision Tree):\")\n",
    "importances_dt = pd.Series(model_dt.feature_importances_, index=X.columns)\n",
    "importances_dt.sort_values().plot(kind='barh', figsize=(10, 6))\n",
    "plt.title(\"Feature Importance (Decision Tree)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fb20bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative 1: Logistic Regression with Polynomial Features\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(X_train[numerical_cols])\n",
    "X_poly_val = poly.transform(X_val[numerical_cols])\n",
    "X_poly_test = poly.transform(X_test[numerical_cols])\n",
    "\n",
    "X_poly_train = pd.concat([pd.DataFrame(X_poly, columns=[f\"poly_{i}\" for i in range(X_poly.shape[1])], index=X_train.index), X_train.drop(columns=numerical_cols)], axis=1)\n",
    "X_poly_val = pd.concat([pd.DataFrame(X_poly_val, columns=[f\"poly_{i}\" for i in range(X_poly_val.shape[1])], index=X_val.index), X_val.drop(columns=numerical_cols)], axis=1)\n",
    "X_poly_test = pd.concat([pd.DataFrame(X_poly_test, columns=[f\"poly_{i}\" for i in range(X_poly_test.shape[1])], index=X_test.index), X_test.drop(columns=numerical_cols)], axis=1)\n",
    "\n",
    "lr_poly_grid = GridSearchCV(LogisticRegression(max_iter=1000), lr_param_grid, cv=3, scoring='accuracy')\n",
    "lr_poly_grid.fit(X_poly_train, y_train)\n",
    "\n",
    "model_lr_poly = LogisticRegression(**lr_poly_grid.best_params_, max_iter=1000)\n",
    "model_lr_poly.fit(X_poly_train, y_train)\n",
    "y_pred_lr_poly = model_lr_poly.predict(X_poly_val)\n",
    "accuracy_lr_poly = accuracy_score(y_val, y_pred_lr_poly)\n",
    "results['Logistic Regression (Poly)'] = accuracy_lr_poly\n",
    "models['Logistic Regression (Poly)'] = model_lr_poly\n",
    "print(f\"Validation Accuracy: {accuracy_lr_poly:.3f}\")\n",
    "print(\"Best parameters:\", lr_poly_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3f4539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative 2: Logistic Regression with Reduced Features\n",
    "\n",
    "top_features = importances_lr.abs().sort_values(ascending=False).head(5).index\n",
    "X_reduced_train = X_train[top_features]\n",
    "X_reduced_val = X_val[top_features]\n",
    "X_reduced_test = X_test[top_features]\n",
    "\n",
    "lr_reduced_grid = GridSearchCV(LogisticRegression(max_iter=1000), lr_param_grid, cv=3, scoring='accuracy')\n",
    "lr_reduced_grid.fit(X_reduced_train, y_train)\n",
    "\n",
    "model_lr_reduced = LogisticRegression(**lr_reduced_grid.best_params_, max_iter=1000)\n",
    "model_lr_reduced.fit(X_reduced_train, y_train)\n",
    "y_pred_lr_reduced = model_lr_reduced.predict(X_reduced_val)\n",
    "accuracy_lr_reduced = accuracy_score(y_val, y_pred_lr_reduced)\n",
    "results['Logistic Regression (Reduced)'] = accuracy_lr_reduced\n",
    "models['Logistic Regression (Reduced)'] = model_lr_reduced\n",
    "print(f\"Validation Accuracy: {accuracy_lr_reduced:.3f}\")\n",
    "print(\"Best parameters:\", lr_reduced_grid.best_params_)\n",
    "print(\"Selected features:\", top_features.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b4ecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative 3: Random Forest\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), rf_param_grid, cv=3, scoring='accuracy')\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "model_rf = RandomForestClassifier(**rf_grid.best_params_, random_state=42)\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred_rf = model_rf.predict(X_val)\n",
    "accuracy_rf = accuracy_score(y_val, y_pred_rf)\n",
    "results['Random Forest'] = accuracy_rf\n",
    "models['Random Forest'] = model_rf\n",
    "print(f\"Validation Accuracy: {accuracy_rf:.3f}\")\n",
    "print(\"Best parameters:\", rf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f62a4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curves \n",
    "def plot_learning_curve(estimator, title, X, y, cv=None, train_sizes=np.linspace(0.1, 1.0, 5)):\n",
    "    train_sizes, train_scores, val_scores = learning_curve(estimator, X, y, cv=cv, train_sizes=train_sizes, scoring='accuracy')\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    val_scores_mean = np.mean(val_scores, axis=1)\n",
    "    val_scores_std = np.std(val_scores, axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, val_scores_mean - val_scores_std, val_scores_mean + val_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, val_scores_mean, 'o-', color=\"g\", label=\"Validation score\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training Examples\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyze fit\n",
    "    if train_scores_mean[-1] > val_scores_mean[-1] + 0.1 and train_scores_mean[-1] > 0.9:\n",
    "        fit_status = \"Overfitting: High training accuracy, low validation accuracy.\"\n",
    "    elif train_scores_mean[-1] < 0.7 and val_scores_mean[-1] < 0.7:\n",
    "        fit_status = \"Underfitting: Both training and validation accuracies are low.\"\n",
    "    else:\n",
    "        fit_status = \"Good fit: Training and validation accuracies are close and reasonable.\"\n",
    "    print(f\"Fit Analysis - {title}: {fit_status}\")\n",
    "    \n",
    "    \n",
    "    if val_scores_mean[-1] < 0.8 and (val_scores_mean[-1] - val_scores_mean[0]) > 0.05:\n",
    "        data_need = \"More training data may help: Validation accuracy is improving with more data.\"\n",
    "    else:\n",
    "        data_need = \"More data may not significantly help: Validation accuracy has plateaued.\"\n",
    "    print(f\"Data Need - {title}: {data_need}\")\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "plot_learning_curve(model_lr, \"Learning Curve (Logistic Regression)\", X_temp, y_temp, cv=cv)\n",
    "plot_learning_curve(model_dt, \"Learning Curve (Decision Tree)\", X_temp, y_temp, cv=cv)\n",
    "plot_learning_curve(model_lr_poly, \"Learning Curve (Logistic Regression - Poly)\", X_poly_train, y_train, cv=cv)\n",
    "plot_learning_curve(model_lr_reduced, \"Learning Curve (Logistic Regression - Reduced)\", X_reduced_train, y_train, cv=cv)\n",
    "plot_learning_curve(model_rf, \"Learning Curve (Random Forest)\", X_temp, y_temp, cv=cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1503db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curves and AUC \n",
    "plt.figure(figsize=(10, 6))\n",
    "for name, model in models.items():\n",
    "    if name == 'Logistic Regression (Poly)':\n",
    "        X_input = X_poly_test\n",
    "    elif name == 'Logistic Regression (Reduced)':\n",
    "        X_input = X_reduced_test\n",
    "    else:\n",
    "        X_input = X_test\n",
    "    \n",
    "    y_pred_proba = model.predict_proba(X_input)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for All Models')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1685dd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision, Recall, and F1 on Test Set\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "print(\"\\n=== Precision, Recall, and F1 on Test Set ===\")\n",
    "for name, model in models.items():\n",
    "    if name == 'Logistic Regression (Poly)':\n",
    "        X_input = X_poly_test\n",
    "    elif name == 'Logistic Regression (Reduced)':\n",
    "        X_input = X_reduced_test\n",
    "    else:\n",
    "        X_input = X_test\n",
    "    \n",
    "    y_pred = model.predict(X_input)\n",
    "    precision = precision_score(y_test, y_pred, average='binary')\n",
    "    recall = recall_score(y_test, y_pred, average='binary')\n",
    "    f1 = f1_score(y_test, y_pred, average='binary')\n",
    "    print(f\"{name}: Precision = {precision:.3f}, Recall = {recall:.3f}, F1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77166fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Errors with Venn Diagram \n",
    "error_indices = {}\n",
    "for name, model in models.items():\n",
    "    if name == 'Logistic Regression (Poly)':\n",
    "        X_input = X_poly_test\n",
    "    elif name == 'Logistic Regression (Reduced)':\n",
    "        X_input = X_reduced_test\n",
    "    else:\n",
    "        X_input = X_test\n",
    "    \n",
    "    y_pred = model.predict(X_input)\n",
    "    errors = set(X_test.index[y_test != y_pred])\n",
    "    error_indices[name] = errors\n",
    "\n",
    "# Venn Diagram for three models (Logistic Regression, Decision Tree, Random Forest)\n",
    "plt.figure(figsize=(8, 6))\n",
    "venn.venn3([error_indices['Logistic Regression'], error_indices['Decision Tree'], error_indices['Random Forest']],\n",
    "           set_labels=('Logistic Regression', 'Decision Tree', 'Random Forest'))\n",
    "plt.title(\"Venn Diagram of Misclassification Errors\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba8900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse Sample Errors \n",
    "print(\"\\n=== Sample Misclassification Analysis ===\")\n",
    "# Select two common errors between Logistic Regression and Decision Tree\n",
    "common_errors_set = error_indices['Logistic Regression'].intersection(error_indices['Decision Tree'])\n",
    "common_errors = list(common_errors_set)[:2]\n",
    "for idx in common_errors:\n",
    "    print(f\"\\nMisclassified Student (Index {idx}):\")\n",
    "    print(\"Features:\", X_test.loc[idx].to_dict())\n",
    "    print(\"True Label:\", y_test.loc[idx])\n",
    "    print(\"Logistic Regression Prediction:\", models['Logistic Regression'].predict(X_test.loc[[idx]])[0])\n",
    "    print(\"Decision Tree Prediction:\", models['Decision Tree'].predict(X_test.loc[[idx]])[0])\n",
    "    print(\"Analysis: This student may have been misclassified due to low InterestLevel_1 or a mismatch between CareerTrack and course requirements.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db262301",
   "metadata": {},
   "source": [
    "# Recommender System "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4dfed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target columns for all courses\n",
    "course_columns = [\n",
    "    {'target': 'Suitable_1', 'interest': 'InterestLevel_1', 'reason': 'Reason_1', 'course': 'BP'},\n",
    "    {'target': 'Suitable_2', 'interest': 'InterestLevel_2', 'reason': 'Reason_2', 'course': 'BI'},\n",
    "    {'target': 'Suitable_3', 'interest': 'InterestLevel_3', 'reason': 'Reason_3', 'course': 'BDCN'},\n",
    "    {'target': 'Suitable_4', 'interest': 'InterestLevel_4', 'reason': 'Reason_4', 'course': 'PCM'},\n",
    "    {'target': 'Suitable_5', 'interest': 'InterestLevel_5', 'reason': 'Reason_5', 'course': 'ADML'}\n",
    "]\n",
    "\n",
    "for course in course_columns:\n",
    "    target_col = course['target']\n",
    "    course_name = course['course']\n",
    "    print(f\"\\n{course_name} ({target_col}):\")\n",
    "    print(f\"Missing values: {df[target_col].isna().sum()} out of {len(df)} ({df[target_col].isna().mean() * 100:.1f}%)\")\n",
    "    print(f\"Unique values: {df[target_col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904f6603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of courses to their ideal CareerTrack\n",
    "course_to_career_mapping = {\n",
    "    'BP': 'Software Development',\n",
    "    'BI': 'Business Analytics',\n",
    "    'BDCN': 'Cybersecurity',\n",
    "    'PCM': 'Project Management / Business Analysis',\n",
    "    'ADML': 'Data Science / AI'\n",
    "}\n",
    "\n",
    "suitability_predictions = pd.DataFrame(index=df.index)\n",
    "\n",
    "for course in course_columns:\n",
    "    target_col = course['target']\n",
    "    interest_col = course['interest']\n",
    "    reason_col = course['reason']\n",
    "    course_name = course['course']\n",
    "    \n",
    "    if df[target_col].isna().sum() > len(df) * 0.8:\n",
    "        print(f\"Skipping {course_name}: Too many missing values in {target_col}\")\n",
    "        suitability_predictions[course_name] = 0  \n",
    "        continue\n",
    "    \n",
    "    \n",
    "    temp_df = df.copy()\n",
    "    temp_df[target_col] = temp_df[target_col].fillna('No')\n",
    "    \n",
    "    temp_categorical_cols = ['Semester', 'LearningStyle', 'CareerTrack', reason_col]\n",
    "    temp_numerical_cols = ['OverallCourseRating', interest_col, 'StudyHours']\n",
    "    \n",
    "    for col in temp_categorical_cols:\n",
    "        temp_df[col] = temp_df[col].fillna(temp_df[col].mode()[0])\n",
    "    for col in temp_numerical_cols:\n",
    "        temp_df[col] = temp_df[col].fillna(temp_df[col].mean())\n",
    "    \n",
    "    print(f\"\\nUnique values in {target_col} for {course_name}:\")\n",
    "    print(temp_df[target_col].unique())\n",
    "    \n",
    "    if temp_df[target_col].dtype in ['int64', 'int32', 'float64']:\n",
    "        if set(temp_df[target_col].unique()).issubset({0, 1}):\n",
    "            print(f\"{target_col} already contains binary values [0, 1]. Skipping mapping.\")\n",
    "        else:\n",
    "            print(f\"Unexpected integer values in {target_col}: {temp_df[target_col].unique()}\")\n",
    "            suitability_predictions[course_name] = 0\n",
    "            continue\n",
    "    else:\n",
    "        temp_df[target_col] = temp_df[target_col].map({'Yes': 1, 'No': 0})\n",
    "    \n",
    "    temp_df = temp_df.dropna(subset=[target_col])\n",
    "    \n",
    "    if temp_df.empty:\n",
    "        print(f\"Skipping {course_name}: No valid target values after mapping\")\n",
    "        suitability_predictions[course_name] = 0  \n",
    "        continue\n",
    "    \n",
    "    temp_encoded = pd.get_dummies(temp_df[temp_categorical_cols], drop_first=True)\n",
    "    temp_X = pd.concat([temp_df[temp_numerical_cols], temp_encoded], axis=1)\n",
    "    temp_y = temp_df[target_col]\n",
    "    \n",
    "    if temp_y.isna().sum() > 0:\n",
    "        print(f\"Error: NaN values found in target for {course_name}\")\n",
    "        suitability_predictions[course_name] = 0  \n",
    "        continue\n",
    "    \n",
    "    temp_model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "    temp_model.fit(temp_X, temp_y)\n",
    "    \n",
    "    full_encoded = pd.get_dummies(df[temp_categorical_cols], drop_first=True)\n",
    "    for col in temp_X.columns:\n",
    "        if col not in full_encoded.columns and col not in temp_numerical_cols:\n",
    "            full_encoded[col] = 0\n",
    "    full_encoded = full_encoded[[col for col in temp_X.columns if col not in temp_numerical_cols]]\n",
    "    full_X = pd.concat([df[temp_numerical_cols], full_encoded], axis=1)\n",
    "    full_X = full_X.fillna(full_X.mean())\n",
    "    full_X = full_X[temp_X.columns]\n",
    "    \n",
    "    full_X_reset = full_X.reset_index(drop=True)\n",
    "    \n",
    "    suitability_probs = temp_model.predict_proba(full_X_reset)[:, 1]\n",
    "    \n",
    "    ideal_career = course_to_career_mapping[course_name]\n",
    "    career_cols = [col for col in temp_X.columns if col.startswith('CareerTrack_')]\n",
    "    \n",
    "    for idx in range(len(suitability_probs)):\n",
    "        for career_col in career_cols:\n",
    "            if full_X_reset.loc[idx, career_col] == 1:\n",
    "                career = career_col.replace('CareerTrack_', '')\n",
    "                if career == ideal_career:\n",
    "                    suitability_probs[idx] *= 2.0  \n",
    "                elif career == 'Data Science / AI' and career != ideal_career:\n",
    "                    suitability_probs[idx] *= 0.5 \n",
    "    \n",
    "    \n",
    "    suitability_probs_df = pd.Series(suitability_probs, index=full_X.index)\n",
    "    \n",
    "    suitability_predictions[course_name] = (suitability_probs_df >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nSuitability Predictions for All Courses (first 5 rows):\")\n",
    "display(suitability_predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90712d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize Course Profiles\n",
    "\n",
    "course_to_career_mapping = {\n",
    "    'BP': 'Software Development',\n",
    "    'BI': 'Business Analytics',\n",
    "    'BDCN': 'Cybersecurity',\n",
    "    'PCM': 'Project Management / Business Analysis',\n",
    "    'ADML': 'Data Science / AI'\n",
    "}\n",
    "\n",
    "course_profiles_summary = {}\n",
    "\n",
    "# Grid for all CareerTrack distribution plots \n",
    "num_courses = len(suitability_predictions.columns)\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(20, 18))  \n",
    "axes = axes.flatten()  \n",
    "\n",
    "for idx, course in enumerate(suitability_predictions.columns):\n",
    "    suitable_students = suitability_predictions[course] == 1\n",
    "    if suitable_students.sum() == 0:\n",
    "        print(f\"No students found suitable for {course}\")\n",
    "        course_profiles_summary[course] = \"No suitable students\"\n",
    "        axes[idx].text(0.5, 0.5, f\"No suitable students for {course}\", \n",
    "                       horizontalalignment='center', verticalalignment='center', fontsize=12)\n",
    "        axes[idx].set_title(f\"CareerTrack Distribution for {course}\", fontsize=14, pad=15)\n",
    "        continue\n",
    "    \n",
    "    suitable_df = df[suitable_students][['CareerTrack', 'LearningStyle']]\n",
    "    \n",
    "    career_counts = suitable_df['CareerTrack'].value_counts(normalize=True) * 100\n",
    "    career_counts = career_counts.head(5)  \n",
    "    \n",
    "    ideal_career = course_to_career_mapping[course]\n",
    "    if ideal_career in career_counts.index:\n",
    "        ideal_career_pct = career_counts[ideal_career]\n",
    "    else:\n",
    "        ideal_career_pct = 0.0\n",
    "    \n",
    "    learning_counts = suitable_df['LearningStyle'].value_counts(normalize=True) * 100\n",
    "    top_learning = learning_counts.index[0]\n",
    "    top_learning_pct = learning_counts.iloc[0]\n",
    "    \n",
    "    summary = f\"{course} is ideal for {ideal_career} ({ideal_career_pct:.1f}%) learners. Top CareerTracks: \"\n",
    "    for career, pct in career_counts.head(2).items():  \n",
    "        summary += f\"{career} ({pct:.1f}%), \"\n",
    "    summary = summary.rstrip(\", \") + f\". Top LearningStyle: {top_learning} ({top_learning_pct:.1f}%).\"\n",
    "    course_profiles_summary[course] = summary\n",
    "    print(summary)\n",
    "    \n",
    "    bars = axes[idx].bar(career_counts.index, career_counts.values, color='skyblue', edgecolor='black')\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        axes[idx].text(bar.get_x() + bar.get_width() / 2, height + 1, f'{height:.1f}%', \n",
    "                       ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    axes[idx].set_title(f\"CareerTrack Distribution for {course}\", fontsize=14, pad=15)\n",
    "    axes[idx].set_xlabel(\"CareerTrack\", fontsize=12)\n",
    "    axes[idx].set_ylabel(\"Percentage\", fontsize=12)\n",
    "    axes[idx].set_ylim(0, max(career_counts.values) + 10)  \n",
    "    axes[idx].tick_params(axis='x', rotation=45, labelsize=10)\n",
    "    \n",
    "    axes[idx].margins(x=0.05)  \n",
    "    plt.setp(axes[idx].get_xticklabels(), ha='right')  \n",
    "\n",
    "if idx < len(axes) - 1:\n",
    "    axes[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5560b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CareerTrack-Focused Recommender System\n",
    "\n",
    "course_dominant_career = {}\n",
    "for course in suitability_predictions.columns:\n",
    "    suitable_students = suitability_predictions[course] == 1\n",
    "    if suitable_students.sum() > 0:\n",
    "        career_counts = df[suitable_students]['CareerTrack'].value_counts(normalize=True)\n",
    "        course_dominant_career[course] = career_counts.index[0]\n",
    "    else:\n",
    "        course_dominant_career[course] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ce15a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recommend courses based on student input\n",
    "def recommend_courses(student_careertrack, student_learningstyle=None):\n",
    "    matching_courses = [course for course, dominant_career in course_dominant_career.items() \n",
    "                       if dominant_career == student_careertrack]\n",
    "    \n",
    "    if not matching_courses:\n",
    "        print(f\"No courses found matching CareerTrack '{student_careertrack}'.\")\n",
    "        return []\n",
    "    \n",
    "    student_data = {\n",
    "        'Semester': df['Semester'].mode()[0],\n",
    "        'LearningStyle': student_learningstyle if student_learningstyle else df['LearningStyle'].mode()[0],\n",
    "        'CareerTrack': student_careertrack,\n",
    "        'OverallCourseRating': df['OverallCourseRating'].mean(),\n",
    "        'StudyHours': df['StudyHours'].mean()\n",
    "    }\n",
    "    \n",
    "    for idx, course_info in enumerate(course_columns):\n",
    "        reason_col = f'Reason_{idx + 1}'\n",
    "        interest_col = f'InterestLevel_{idx + 1}'\n",
    "        student_data[reason_col] = df[reason_col].mode()[0] if reason_col in df.columns else 'Unknown'\n",
    "        student_data[interest_col] = df[interest_col].mean() if interest_col in df.columns else 0.0\n",
    "    \n",
    "    student_df = pd.DataFrame([student_data])\n",
    "\n",
    "    recommendations = []\n",
    "    models_per_course = {}\n",
    "    for course in matching_courses:\n",
    "        model, feature_cols = models_per_course[course]\n",
    "        course_idx = [c['course'] for c in course_columns].index(course)\n",
    "        temp_categorical_cols = ['Semester', 'LearningStyle', 'CareerTrack', f'Reason_{course_idx + 1}']\n",
    "        temp_numerical_cols = ['OverallCourseRating', f'InterestLevel_{course_idx + 1}', 'StudyHours']\n",
    "        \n",
    "        for col in temp_categorical_cols + temp_numerical_cols:\n",
    "            if col not in student_df.columns:\n",
    "                print(f\"Warning: Column '{col}' not found in student_df. Adding with default value.\")\n",
    "                if col in temp_numerical_cols:\n",
    "                    student_df[col] = 0.0\n",
    "                else:\n",
    "                    student_df[col] = 'Unknown'\n",
    "        \n",
    "        temp_encoded = pd.get_dummies(student_df[temp_categorical_cols], drop_first=True)\n",
    "        for col in feature_cols:\n",
    "            if col not in temp_encoded.columns and col not in temp_numerical_cols:\n",
    "                temp_encoded[col] = 0\n",
    "        temp_encoded = temp_encoded[[col for col in feature_cols if col not in temp_numerical_cols]]\n",
    "        temp_X = pd.concat([student_df[temp_numerical_cols], temp_encoded], axis=1)\n",
    "        temp_X = temp_X.fillna(temp_X.mean())\n",
    "        temp_X = temp_X[feature_cols]\n",
    "        prob = model.predict_proba(temp_X)[0][1]\n",
    "        recommendations.append((course, prob))\n",
    "    \n",
    "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbf9958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Recommend courses for a student Data Science / AI student \n",
    "print(\"\\nStudent Profile: CareerTrack = 'Data Science / AI'\")\n",
    "recommendations = recommend_courses(student_careertrack=\"Data Science / AI\")\n",
    "for course, prob in recommendations:\n",
    "    print(f\"Course: {course}, Suitability Probability = {prob:.3f} ({course_profiles_summary[course]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c006d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build models_per_course for both baseline and weighted strategies\n",
    "models_per_course_baseline = {}\n",
    "models_per_course_weighted = {}\n",
    "\n",
    "for course in course_columns:\n",
    "    target_col = course['target']\n",
    "    interest_col = course['interest']\n",
    "    reason_col = course['reason']\n",
    "    course_name = course['course']\n",
    "\n",
    "    temp_df = df.copy()\n",
    "    temp_df[target_col] = temp_df[target_col].fillna('No')\n",
    "    temp_categorical_cols = ['Semester', 'LearningStyle', 'CareerTrack', reason_col]\n",
    "    temp_numerical_cols = ['OverallCourseRating', interest_col, 'StudyHours']\n",
    "\n",
    "    for col in temp_categorical_cols:\n",
    "        temp_df[col] = temp_df[col].fillna(temp_df[col].mode()[0])\n",
    "    for col in temp_numerical_cols:\n",
    "        temp_df[col] = temp_df[col].fillna(temp_df[col].mean())\n",
    "\n",
    "    temp_df[target_col] = temp_df[target_col].map({'Yes': 1, 'No': 0})\n",
    "    temp_df = temp_df.dropna(subset=[target_col])\n",
    "    if temp_df.empty:\n",
    "        continue\n",
    "\n",
    "    temp_encoded = pd.get_dummies(temp_df[temp_categorical_cols], drop_first=True)\n",
    "    temp_X = pd.concat([temp_df[temp_numerical_cols], temp_encoded], axis=1)\n",
    "    temp_y = temp_df[target_col]\n",
    "\n",
    "    # Baseline model \n",
    "    model_baseline = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "    model_baseline.fit(temp_X, temp_y)\n",
    "    models_per_course_baseline[course_name] = (model_baseline, temp_X.columns.tolist())\n",
    "\n",
    "    # Weighted model\n",
    "    model_weighted = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "    model_weighted.fit(temp_X, temp_y)\n",
    "    models_per_course_weighted[course_name] = (model_weighted, temp_X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7907fdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_courses_baseline(student_careertrack, student_learningstyle=None):\n",
    "    matching_courses = [course for course, dominant_career in course_dominant_career.items() \n",
    "                       if dominant_career == student_careertrack]\n",
    "    \n",
    "    if not matching_courses:\n",
    "        print(f\"No courses found matching CareerTrack '{student_careertrack}'.\")\n",
    "        return []\n",
    "    \n",
    "    student_data = {\n",
    "        'Semester': df['Semester'].mode()[0],\n",
    "        'LearningStyle': student_learningstyle if student_learningstyle else df['LearningStyle'].mode()[0],\n",
    "        'CareerTrack': student_careertrack,\n",
    "        'OverallCourseRating': df['OverallCourseRating'].mean(),\n",
    "        'StudyHours': df['StudyHours'].mean()\n",
    "    }\n",
    "    \n",
    "    for idx, course_info in enumerate(course_columns):\n",
    "        reason_col = f'Reason_{idx + 1}'\n",
    "        interest_col = f'InterestLevel_{idx + 1}'\n",
    "        student_data[reason_col] = df[reason_col].mode()[0] if reason_col in df.columns else 'Unknown'\n",
    "        student_data[interest_col] = df[interest_col].mean() if interest_col in df.columns else 0.0\n",
    "    \n",
    "    student_df = pd.DataFrame([student_data])\n",
    "\n",
    "    recommendations = []\n",
    "    for course in matching_courses:\n",
    "        model, feature_cols = models_per_course_baseline[course]\n",
    "        course_idx = [c['course'] for c in course_columns].index(course)\n",
    "        temp_categorical_cols = ['Semester', 'LearningStyle', 'CareerTrack', f'Reason_{course_idx + 1}']\n",
    "        temp_numerical_cols = ['OverallCourseRating', f'InterestLevel_{course_idx + 1}', 'StudyHours']\n",
    "        \n",
    "        for col in temp_categorical_cols + temp_numerical_cols:\n",
    "            if col not in student_df.columns:\n",
    "                print(f\"Warning: Column '{col}' not found in student_df. Adding with default value.\")\n",
    "                if col in temp_numerical_cols:\n",
    "                    student_df[col] = 0.0\n",
    "                else:\n",
    "                    student_df[col] = 'Unknown'\n",
    "        \n",
    "        temp_encoded = pd.get_dummies(student_df[temp_categorical_cols], drop_first=True)\n",
    "        for col in feature_cols:\n",
    "            if col not in temp_encoded.columns and col not in temp_numerical_cols:\n",
    "                temp_encoded[col] = 0\n",
    "        temp_encoded = temp_encoded[[col for col in feature_cols if col not in temp_numerical_cols]]\n",
    "        temp_X = pd.concat([student_df[temp_numerical_cols], temp_encoded], axis=1)\n",
    "        temp_X = temp_X.fillna(temp_X.mean())\n",
    "        temp_X = temp_X[feature_cols]\n",
    "        prob = model.predict_proba(temp_X)[0][1]\n",
    "        recommendations.append((course, prob))\n",
    "    \n",
    "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "    return recommendations\n",
    "\n",
    "def recommend_courses_weighted(student_careertrack, student_learningstyle=None):\n",
    "    # ... (same as recommend_courses, but use models_per_course_weighted)\n",
    "    # Apply the weighting logic (multiply probabilities for ideal career, etc.)\n",
    "    matching_courses = [course for course, dominant_career in course_dominant_career.items() \n",
    "                       if dominant_career == student_careertrack]\n",
    "    \n",
    "    if not matching_courses:\n",
    "        print(f\"No courses found matching CareerTrack '{student_careertrack}'.\")\n",
    "        return []\n",
    "    \n",
    "    student_data = {\n",
    "        'Semester': df['Semester'].mode()[0],\n",
    "        'LearningStyle': student_learningstyle if student_learningstyle else df['LearningStyle'].mode()[0],\n",
    "        'CareerTrack': student_careertrack,\n",
    "        'OverallCourseRating': df['OverallCourseRating'].mean(),\n",
    "        'StudyHours': df['StudyHours'].mean()\n",
    "    }\n",
    "    \n",
    "    for idx, course_info in enumerate(course_columns):\n",
    "        reason_col = f'Reason_{idx + 1}'\n",
    "        interest_col = f'InterestLevel_{idx + 1}'\n",
    "        student_data[reason_col] = df[reason_col].mode()[0] if reason_col in df.columns else 'Unknown'\n",
    "        student_data[interest_col] = df[interest_col].mean() if interest_col in df.columns else 0.0\n",
    "    \n",
    "    student_df = pd.DataFrame([student_data])\n",
    "\n",
    "    recommendations = []\n",
    "    for course in matching_courses:\n",
    "        model, feature_cols = models_per_course_weighted[course]\n",
    "        course_idx = [c['course'] for c in course_columns].index(course)\n",
    "        temp_categorical_cols = ['Semester', 'LearningStyle', 'CareerTrack', f'Reason_{course_idx + 1}']\n",
    "        temp_numerical_cols = ['OverallCourseRating', f'InterestLevel_{course_idx + 1}', 'StudyHours']\n",
    "        \n",
    "        for col in temp_categorical_cols + temp_numerical_cols:\n",
    "            if col not in student_df.columns:\n",
    "                print(f\"Warning: Column '{col}' not found in student_df. Adding with default value.\")\n",
    "                if col in temp_numerical_cols:\n",
    "                    student_df[col] = 0.0\n",
    "                else:\n",
    "                    student_df[col] = 'Unknown'\n",
    "        \n",
    "        temp_encoded = pd.get_dummies(student_df[temp_categorical_cols], drop_first=True)\n",
    "        for col in feature_cols:\n",
    "            if col not in temp_encoded.columns and col not in temp_numerical_cols:\n",
    "                temp_encoded[col] = 0\n",
    "        temp_encoded = temp_encoded[[col for col in feature_cols if col not in temp_numerical_cols]]\n",
    "        temp_X = pd.concat([student_df[temp_numerical_cols], temp_encoded], axis=1)\n",
    "        temp_X = temp_X.fillna(temp_X.mean())\n",
    "        temp_X = temp_X[feature_cols]\n",
    "        prob = model.predict_proba(temp_X)[0][1]\n",
    "        recommendations.append((course, prob))\n",
    "    \n",
    "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24474616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# For all students in the test set\n",
    "test_indices = X_test.index\n",
    "baseline_recs = []\n",
    "weighted_recs = []\n",
    "true_careers = []\n",
    "\n",
    "for idx in test_indices:\n",
    "    student = df.loc[idx]\n",
    "    career = student['CareerTrack']\n",
    "    learning = student['LearningStyle']\n",
    "    true_careers.append(career)\n",
    "\n",
    "    # Baseline\n",
    "    recs_base = recommend_courses_baseline(career, learning)\n",
    "    top_base = recs_base[0][0] if recs_base else None\n",
    "    baseline_recs.append(top_base)\n",
    "\n",
    "    # Weighted\n",
    "    recs_weight = recommend_courses_weighted(career, learning)\n",
    "    top_weight = recs_weight[0][0] if recs_weight else None\n",
    "    weighted_recs.append(top_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040c1148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Contingency tables: rows = true career, columns = recommended course\n",
    "def build_contingency(recs, true_careers, course_list):\n",
    "    table = []\n",
    "    for career in set(true_careers):\n",
    "        row = []\n",
    "        for course in course_list:\n",
    "            count = sum((t == career) and (r == course) for t, r in zip(true_careers, recs))\n",
    "            row.append(count)\n",
    "        table.append(row)\n",
    "    return table\n",
    "\n",
    "course_list = [c['course'] for c in course_columns]\n",
    "contingency_baseline = build_contingency(baseline_recs, true_careers, course_list)\n",
    "contingency_weighted = build_contingency(weighted_recs, true_careers, course_list)\n",
    "\n",
    "# Chi-square test for independence\n",
    "chi2_base, p_base, _, _ = chi2_contingency(contingency_baseline)\n",
    "chi2_weight, p_weight, _, _ = chi2_contingency(contingency_weighted)\n",
    "\n",
    "print(f\"Baseline strategy: Chi2 = {chi2_base:.2f}, p = {p_base:.4f}\")\n",
    "print(f\"Weighted strategy: Chi2 = {chi2_weight:.2f}, p = {p_weight:.4f}\")\n",
    "\n",
    "if p_weight < 0.05 and p_weight < p_base:\n",
    "    print(\"Weighted strategy shows significantly improved alignment with career aspirations (p < 0.05).\")\n",
    "else:\n",
    "    print(\"No significant improvement in alignment with career aspirations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9520ada0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
